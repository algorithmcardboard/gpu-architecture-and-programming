\documentclass{article}

\usepackage{tabulary}
\usepackage{hyperref}

\begin{document}
\title{GPU - hw 1}
\author{Anirudhan J. Rajagopalan --- N18824115}
\maketitle

\newpage

\section{Q1}

\begin{tabulary}{\textwidth}{LLLLL}
    \bfseries
    Gpu Model & \bfseries Memory (GB) &\bfseries Num Cores &\bfseries Bandwidth (GB/sec) &\bfseries Year \mdseries \\
    \hline \\
    GTX Titan X~\cite{gpu:titan_x} & 12 GB GDDR5 & 3072 & 336.5 & March, 2015 \\\\
    GTX 980 Ti~\cite{gpu:980_ti} & 6GB GDDR5 & 2816 & 336.5 & June, 2015 \\\\
    GTX 1080~\cite{gpu:gtx_1080} &  8 GB GDDR5X & 2560 & 320 & May, 2016    \\\\
    GTX 1070~\cite{gpu:gtx_1070} & 8 GB GDDR5 & 1920 & 256 & June, 2016 \\\\
    GTX 1060~\cite{gpu:gtx_1060} & 6 GB GDDR5 & 1280 & 192 & July, 2016 \\\\
\end{tabulary}

\section{Q2}
\subsection{Bottlenecks}
The main bottleneck in GPUs is its memory.   While CPU's have evloved to use memory on the order of 72 GB or even 144GBs, GPUs have a maximum of 12GB so far.

\subsection{Bottleneck set to continue}
Based on the table above, we can see that the memory bottleneck can be expected to continue in the near future.


\section{Q3}
\subsection{Five applications of GPU}
GPUs excel in performing simple operations in parallel streams of data.  Listed below are five applications of GPUs that fit this bill.
\begin{enumerate}
    \item  Computational Finance - Simulations and in Monte Carlo simulations.
    \item  Deep Learning \& Machine Learning - Many of the deep learning problems are forumlated as matrix operations which can be done efficiently in GPUs.
    \item  Crypto currency mining - Since crypto currency mining is a repeated calculation of SHA256 checksums~\cite{so:bitcoin}
    \item  Graphics rendering - Graphics and computer animations are inherently small vector operations done at multiple pixel positions.
    \item  Defense and Intelligence~\cite{gpu:defence_intelligence} -  Defense and intelligence requires data from wide array of sensors which has to be collected parallely and converted into actionable items in real time.  GPUs help in this process.
\end{enumerate}

\section{Q4}
\subsection{Impact of the amount of data on GPU performance}
Yes, The amount of data has a definite influence on the performance of the system.  If the amount of data is small, then moving the information from CPU's memory to GPU will be a big component of the time taken to perform the task and due to this, we might not observe any definite performance gains.  But if the amount of data is huge, using GPUs will most certainly give better performance in this scenario.

\section{Q5}
\subsection{Beneficial for GPU implementation?}
\subsubsection{Finding whether a number exists in an array of 10M numbers}
This can essentially be done as performing the simple equals operation on 10M numbers at the same time.  Since this involves a simple operation on independent data, we can implement this in a GPU.
\subsubsection{Calculating the first 1M fibonacci numbers}
Fibonacci number calculation is essentially a sequential operation which is difficult to parallelize.  So it is not well suited for GPU implemntation.
\subsubsection{Multiplying 1000$\times$1000 matrices}
Matrix multiplication is well suited for GPU implementation.  There are parallel algorithms for matrix multiplication which can then be implemented using GPUs.

\bibliographystyle{plain}
\bibliography{references}

\end{document}
